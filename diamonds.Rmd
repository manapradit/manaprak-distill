---
title: "Diamonds"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r library, include=FALSE}
# Library required in this analysis
library(tidyverse)
library(plyr)
library(psych)
library(dlookr)
library(corrgram)
library(ggstatsplot)
```

# STA 518 Project
# Overview

Diamonds take billions of years to form and not all of them survive the long journey. This project aims to predict diamond price and create interactive application to estimate the input characteristic. We run regression using diamonds dataset from Tidyverse package, which consists of 53940 round diamonds and 10 variables. The final model use cut, carat, color, and clarity to estimate the price. (r2 = 90.5)

# Data Description

I found the dataset from Kaggle website (https://www.kaggle.com/shivam2503/diamonds). It can also be downloaded from R Tidyverse package, called diamonds. The data set consist of round cut diamonds from Tiffany & Co's snapshot price list in 2017. The original dataset includes 53940 samples and 10 variables. However, this analysis will contain house that has up to six bedrooms and dropped the dataset to 53920 and 10 variables. 

|variable|Type|Detail|
|--------|--------|---------------------------------------------------|
|price   |Numeric |price in US dollars|
|carat   |Numeric |weight of the diamond|
|cut     |Ordinal |quality of the cut (Fair, Good, Very Good, Premium, Ideal)|
|color   |Ordinal |diamond color, from D (best) to J (worst)|
|clarity |Ordinal |a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))|
|x       |Numeric |length in mm (0–10.74)|
|y       |Numeric |width in mm (0–58.9)|
|z       |Numeric |depth in mm (0–31.8)|
|depth   |Numeric |total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43–79)|
|table   |Numeric |width of top of diamond relative to widest point (43–95)|

```{r Import data}
# Look at the diamonds dataset from Tidyverse package 
glimpse(diamonds)
```

# Data cleaning, validation and preparation

The diamonds data requires small cleaning as it is very clean and well organized. Since I will perform regression, I decided to convert the 3 ordinal variables to numeric scale. I also remove observation with value 0 in x, y, and z variables because it does not make sense if the dimension is 0. 

```{r Data cleaning}
# use plyr::revalue to convert cut, color and clarity scales to number
data <- diamonds
data$color <- as.numeric(revalue(data$color, c("D"=1, "E"=2, "F"=3, "G"=4, "H"=5, "I"=6, "J"=7)))
data$clarity <- as.numeric(revalue(data$clarity, c("IF"=1, "VVS1"=2, "VVS2"=3, "VS1"=4, "VS2"=5, "SI1"=6, "SI2"=7, "I1"=8)))
data$cut <- as.numeric(revalue(data$cut, c("Fair"=1, "Good"=2, "Very Good"=3, "Premium"=4, "Ideal"=5)))

data <- data %>%
  #filter(cut %in% c("Ideal", "Premium", "Very Good")) %>% 
  filter(x>0, y>0, z>0) 

#describe(data, ranges = FALSE)
summary(data)
```

```{r Frequency of ordinal variable}
dplyr::count(data,cut)
dplyr::count(data,color)
dplyr::count(data,clarity)
```

```{r normality}
#dlookr::plot_normality(data)
```

```{r EDA price carat}
ggplot(data, aes(price, carat, colour = as.factor(cut))) + geom_point() 
ggplot(data, aes(price, carat, fill = as.factor(cut))) + geom_boxplot()
```

```{r Column name}
colnames(data)
```

# Correlations 

The correlation plot below show relationships between the dependent variable and independent variables. Variable x, y, and z have significantly high positive relations with each other at more than 0.96. All 3 variables also highly correlate to carat variable. While, the relation between dependent variable with cut and depth has very small negative relation. Therefore, I will remove variable x, y, and z to prevent multicollinearity.

```{r EDA Correlogram}
cor_data <- data %>% 
  dplyr::select(price,carat,cut,color,clarity,depth,table,x,y,z)

#library("corrgram")
corrgram(cor_data,
upper.panel=panel.cor, main="Correlation",
#lower.panel=corrgram::panel.ellipse,
diag.panel=panel.density)
```

```{r EDA Correlogram2}
#library(ggstatsplot)
# correlogram
ggstatsplot::ggcorrmat(
  data = cor_data,
  type = "parametric", # parametric for Pearson, nonparametric for Spearman's correlation
  colors = c("darkred", "white", "steelblue") # change default colors
)
```

```{r VIF, echo=FALSE }
# Use variance inflation factor (VIF) to check that there are no two or more independent variables that predict each other.
library(regclass)
VIF(lm(price~carat+cut+color+clarity+depth+table+x+y+z, data=data))
VIF(lm(price~carat+cut+color+clarity+depth+table, data=data))
```

# Model selection

## Data division into train data and test data

We will randomly divide the data into train data and test data. The 70 percent is train data which has 37744 observations. The train data will be used to predict the model and the test data will be used to fit the final model to observe the model accuracy. 

```{r Train test data}
data2 <- data %>% 
  dplyr::select(price,carat,cut,color,clarity,depth,table,x,y,z)

# split data for training data and test data
set.seed(789)
train = data2 %>%
sample_frac(0.7)
test = data2 %>%
setdiff(train)
```

## Data subsetting

```{r Subsetting}
library(leaps)
regfit_full = regsubsets(price ~ carat+cut+color+clarity+depth+table, data=train)
summary(regfit_full)

plot(regfit_full, scale="bic")
plot(regfit_full, scale="r2")
```

```{r Model with 6 variables}
fit.lm6 <- lm(price ~ carat+cut+color+clarity+depth+table, data = train)

fit.lm6  %>% 
  broom::tidy()

fit.lm6  %>% 
  broom::augment()

fit.lm6  %>% 
  broom::glance()

pred.lm6 <- predict(fit.lm6, test)
mean((pred.lm6 - test$price)^2)
test.avg <- mean(test$price)
ols6.r2 <- 1 - mean((pred.lm6 - test$price)^2) / mean((test.avg - test$price)^2)
cat("R-square:" , ols6.r2)
summary(fit.lm6)
```

# I pick this model

price = -7.165 + 8776.430carat + 165.511cut - 318.820color - 518.648clarity

```{r Model with 4 variables}
fit.lm4 <- lm(price ~ carat+cut+color+clarity, data = train)

fit.lm4  %>% 
  broom::tidy()

fit.lm4  %>% 
  broom::augment()

fit.lm4  %>% 
  broom::glance()

pred.lm4 <- predict(fit.lm4, test)
mean((pred.lm4 - test$price)^2)
ols4.r2 <- 1 - mean((pred.lm4 - test$price)^2) / mean((mean(test$price) - test$price)^2)
cat("R-square:" , ols4.r2)
summary(fit.lm4)
```




