{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-01T18:13:34-05:00"
    },
    {
      "path": "diamonds.html",
      "title": "Diamonds",
      "author": [],
      "contents": "\r\nSTA 518 Project\r\nOverview\r\nDiamonds take billions of years to form and not all of them survive the long journey. This project aims to predict diamond price and create interactive application to estimate the input characteristic. We run regression using diamonds dataset from Tidyverse package, which consists of 53940 round diamonds and 10 variables. The final model use cut, carat, color, and clarity to estimate the price. (r2 = 90.5)\r\nData Description\r\nI found the dataset from Kaggle website (https://www.kaggle.com/shivam2503/diamonds). It can also be downloaded from R Tidyverse package, called diamonds. The data set consist of round cut diamonds from Tiffany & Co’s snapshot price list in 2017. The original dataset includes 53940 samples and 10 variables. However, this analysis will contain house that has up to six bedrooms and dropped the dataset to 53920 and 10 variables.\r\nvariable\r\nType\r\nDetail\r\nprice\r\nNumeric\r\nprice in US dollars\r\ncarat\r\nNumeric\r\nweight of the diamond\r\ncut\r\nOrdinal\r\nquality of the cut (Fair, Good, Very Good, Premium, Ideal)\r\ncolor\r\nOrdinal\r\ndiamond color, from D (best) to J (worst)\r\nclarity\r\nOrdinal\r\na measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\r\nx\r\nNumeric\r\nlength in mm (0–10.74)\r\ny\r\nNumeric\r\nwidth in mm (0–58.9)\r\nz\r\nNumeric\r\ndepth in mm (0–31.8)\r\ndepth\r\nNumeric\r\ntotal depth percentage = z / mean(x, y) = 2 * z / (x + y) (43–79)\r\ntable\r\nNumeric\r\nwidth of top of diamond relative to widest point (43–95)\r\n\r\n\r\n# Look at the diamonds dataset from Tidyverse package \r\nglimpse(diamonds)\r\n\r\n\r\nRows: 53,940\r\nColumns: 10\r\n$ carat   <dbl> 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22~\r\n$ cut     <ord> Ideal, Premium, Good, Premium, Good, Very Good, Very~\r\n$ color   <ord> E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J~\r\n$ clarity <ord> SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, ~\r\n$ depth   <dbl> 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1~\r\n$ table   <dbl> 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, ~\r\n$ price   <int> 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 33~\r\n$ x       <dbl> 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87~\r\n$ y       <dbl> 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78~\r\n$ z       <dbl> 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49~\r\n\r\nData cleaning, validation and preparation\r\nThe diamonds data requires small cleaning as it is very clean and well organized. Since I will perform regression, I decided to convert the 3 ordinal variables to numeric scale. I also remove observation with value 0 in x, y, and z variables because it does not make sense if the dimension is 0.\r\n\r\n\r\n# use plyr::revalue to convert cut, color and clarity scales to number\r\ndata <- diamonds\r\ndata$color <- as.numeric(revalue(data$color, c(\"D\"=1, \"E\"=2, \"F\"=3, \"G\"=4, \"H\"=5, \"I\"=6, \"J\"=7)))\r\ndata$clarity <- as.numeric(revalue(data$clarity, c(\"IF\"=1, \"VVS1\"=2, \"VVS2\"=3, \"VS1\"=4, \"VS2\"=5, \"SI1\"=6, \"SI2\"=7, \"I1\"=8)))\r\ndata$cut <- as.numeric(revalue(data$cut, c(\"Fair\"=1, \"Good\"=2, \"Very Good\"=3, \"Premium\"=4, \"Ideal\"=5)))\r\n\r\ndata <- data %>%\r\n  #filter(cut %in% c(\"Ideal\", \"Premium\", \"Very Good\")) %>% \r\n  filter(x>0, y>0, z>0) \r\n\r\n#describe(data, ranges = FALSE)\r\nsummary(data)\r\n\r\n\r\n     carat             cut            color          clarity     \r\n Min.   :0.2000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \r\n 1st Qu.:0.4000   1st Qu.:3.000   1st Qu.:2.000   1st Qu.:3.000  \r\n Median :0.7000   Median :4.000   Median :4.000   Median :4.000  \r\n Mean   :0.7977   Mean   :3.904   Mean   :3.594   Mean   :4.052  \r\n 3rd Qu.:1.0400   3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:5.000  \r\n Max.   :5.0100   Max.   :5.000   Max.   :7.000   Max.   :8.000  \r\n     depth           table           price             x         \r\n Min.   :43.00   Min.   :43.00   Min.   :  326   Min.   : 3.730  \r\n 1st Qu.:61.00   1st Qu.:56.00   1st Qu.:  949   1st Qu.: 4.710  \r\n Median :61.80   Median :57.00   Median : 2401   Median : 5.700  \r\n Mean   :61.75   Mean   :57.46   Mean   : 3931   Mean   : 5.732  \r\n 3rd Qu.:62.50   3rd Qu.:59.00   3rd Qu.: 5323   3rd Qu.: 6.540  \r\n Max.   :79.00   Max.   :95.00   Max.   :18823   Max.   :10.740  \r\n       y                z        \r\n Min.   : 3.680   Min.   : 1.07  \r\n 1st Qu.: 4.720   1st Qu.: 2.91  \r\n Median : 5.710   Median : 3.53  \r\n Mean   : 5.735   Mean   : 3.54  \r\n 3rd Qu.: 6.540   3rd Qu.: 4.04  \r\n Max.   :58.900   Max.   :31.80  \r\n\r\n\r\n\r\ndplyr::count(data,cut)\r\n\r\n\r\n# A tibble: 5 x 2\r\n    cut     n\r\n  <dbl> <int>\r\n1     1  1609\r\n2     2  4902\r\n3     3 12081\r\n4     4 13780\r\n5     5 21548\r\n\r\ndplyr::count(data,color)\r\n\r\n\r\n# A tibble: 7 x 2\r\n  color     n\r\n  <dbl> <int>\r\n1     1  6774\r\n2     2  9797\r\n3     3  9538\r\n4     4 11284\r\n5     5  8298\r\n6     6  5421\r\n7     7  2808\r\n\r\ndplyr::count(data,clarity)\r\n\r\n\r\n# A tibble: 8 x 2\r\n  clarity     n\r\n    <dbl> <int>\r\n1       1   738\r\n2       2  9185\r\n3       3 13063\r\n4       4 12254\r\n5       5  8170\r\n6       6  5066\r\n7       7  3654\r\n8       8  1790\r\n\r\n\r\n\r\n#dlookr::plot_normality(data)\r\n\r\n\r\n\r\n\r\n\r\nggplot(data, aes(price, carat, colour = as.factor(cut))) + geom_point() \r\n\r\n\r\n\r\nggplot(data, aes(price, carat, fill = as.factor(cut))) + geom_boxplot()\r\n\r\n\r\n\r\n\r\n\r\n\r\ncolnames(data)\r\n\r\n\r\n [1] \"carat\"   \"cut\"     \"color\"   \"clarity\" \"depth\"   \"table\"  \r\n [7] \"price\"   \"x\"       \"y\"       \"z\"      \r\n\r\nCorrelations\r\nThe correlation plot below show relationships between the dependent variable and independent variables. Variable x, y, and z have significantly high positive relations with each other at more than 0.96. All 3 variables also highly correlate to carat variable. While, the relation between dependent variable with cut and depth has very small negative relation. Therefore, I will remove variable x, y, and z to prevent multicollinearity.\r\n\r\n\r\ncor_data <- data %>% \r\n  dplyr::select(price,carat,cut,color,clarity,depth,table,x,y,z)\r\n\r\n#library(\"corrgram\")\r\ncorrgram(cor_data,\r\nupper.panel=panel.cor, main=\"Correlation\",\r\n#lower.panel=corrgram::panel.ellipse,\r\ndiag.panel=panel.density)\r\n\r\n\r\n\r\n\r\n\r\n\r\n#library(ggstatsplot)\r\n# correlogram\r\nggstatsplot::ggcorrmat(\r\n  data = cor_data,\r\n  type = \"parametric\", # parametric for Pearson, nonparametric for Spearman's correlation\r\n  colors = c(\"darkred\", \"white\", \"steelblue\") # change default colors\r\n)\r\n\r\n\r\n\r\n\r\n\r\n    carat       cut     color   clarity     depth     table         x \r\n24.838037  1.483701  1.120603  1.230140  1.807764  1.580987 64.340380 \r\n        y         z \r\n20.733711 29.940364 \r\n   carat      cut    color  clarity    depth    table \r\n1.297629 1.482007 1.118782 1.200325 1.320529 1.576594 \r\n\r\nModel selection\r\nData division into train data and test data\r\nWe will randomly divide the data into train data and test data. The 70 percent is train data which has 37744 observations. The train data will be used to predict the model and the test data will be used to fit the final model to observe the model accuracy.\r\n\r\n\r\ndata2 <- data %>% \r\n  dplyr::select(price,carat,cut,color,clarity,depth,table,x,y,z)\r\n\r\n# split data for training data and test data\r\nset.seed(789)\r\ntrain = data2 %>%\r\nsample_frac(0.7)\r\ntest = data2 %>%\r\nsetdiff(train)\r\n\r\n\r\n\r\nData subsetting\r\n\r\n\r\nlibrary(leaps)\r\nregfit_full = regsubsets(price ~ carat+cut+color+clarity+depth+table, data=train)\r\nsummary(regfit_full)\r\n\r\n\r\nSubset selection object\r\nCall: regsubsets.formula(price ~ carat + cut + color + clarity + depth + \r\n    table, data = train)\r\n6 Variables  (and intercept)\r\n        Forced in Forced out\r\ncarat       FALSE      FALSE\r\ncut         FALSE      FALSE\r\ncolor       FALSE      FALSE\r\nclarity     FALSE      FALSE\r\ndepth       FALSE      FALSE\r\ntable       FALSE      FALSE\r\n1 subsets of each size up to 6\r\nSelection Algorithm: exhaustive\r\n         carat cut color clarity depth table\r\n1  ( 1 ) \"*\"   \" \" \" \"   \" \"     \" \"   \" \"  \r\n2  ( 1 ) \"*\"   \" \" \" \"   \"*\"     \" \"   \" \"  \r\n3  ( 1 ) \"*\"   \" \" \"*\"   \"*\"     \" \"   \" \"  \r\n4  ( 1 ) \"*\"   \"*\" \"*\"   \"*\"     \" \"   \" \"  \r\n5  ( 1 ) \"*\"   \"*\" \"*\"   \"*\"     \"*\"   \" \"  \r\n6  ( 1 ) \"*\"   \"*\" \"*\"   \"*\"     \"*\"   \"*\"  \r\n\r\nplot(regfit_full, scale=\"bic\")\r\n\r\n\r\n\r\nplot(regfit_full, scale=\"r2\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nfit.lm6 <- lm(price ~ carat+cut+color+clarity+depth+table, data = train)\r\n\r\nfit.lm6  %>% \r\n  broom::tidy()\r\n\r\n\r\n# A tibble: 7 x 5\r\n  term        estimate std.error statistic  p.value\r\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\r\n1 (Intercept)    -63.0    460.      -0.137 8.91e- 1\r\n2 carat         8785.      15.2    579.    0       \r\n3 cut            132.       6.88    19.2   5.20e-82\r\n4 color         -317.       3.93   -80.6   0       \r\n5 clarity        515.       4.21   123.    0       \r\n6 depth          -50.1      5.09    -9.84  7.90e-23\r\n7 table          -24.2      3.56    -6.81  9.69e-12\r\n\r\nfit.lm6  %>% \r\n  broom::augment()\r\n\r\n\r\n# A tibble: 37,744 x 13\r\n   price carat   cut color clarity depth table .fitted  .resid    .hat\r\n   <int> <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>\r\n 1  3985  0.93     5     5       3  61.6    54   4339. -354.   1.50e-4\r\n 2  1046  0.31     4     4       7  59.5    60   1098.  -51.6  2.10e-4\r\n 3  2959  0.7      3     3       5  60.1    58   3696. -737.   1.23e-4\r\n 4  4876  1.01     5     5       3  62.3    59   4885.   -9.18 1.64e-4\r\n 5   630  0.3      1     2       3  64.5    49   -799. 1429.   1.08e-3\r\n 6   462  0.26     5     5       5  62.2    55   -571. 1033.   1.29e-4\r\n 7   734  0.31     4     2       5  61      58    674.   60.0  7.70e-5\r\n 8  2936  0.74     5     3       4  60.5    59   3752. -816.   9.70e-5\r\n 9  1294  0.44     5     1       5  61.6    56   2284. -990.   1.18e-4\r\n10  4201  0.91     4     5       4  61.9    59   4410. -209.   6.84e-5\r\n# ... with 37,734 more rows, and 3 more variables: .sigma <dbl>,\r\n#   .cooksd <dbl>, .std.resid <dbl>\r\n\r\nfit.lm6  %>% \r\n  broom::glance()\r\n\r\n\r\n# A tibble: 1 x 12\r\n  r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC\r\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>\r\n1     0.905         0.905 1226.    60155.       0     6 -3.22e5 6.44e5\r\n# ... with 4 more variables: BIC <dbl>, deviance <dbl>,\r\n#   df.residual <int>, nobs <int>\r\n\r\npred.lm6 <- predict(fit.lm6, test)\r\nmean((pred.lm6 - test$price)^2)\r\n\r\n\r\n[1] 1558490\r\n\r\ntest.avg <- mean(test$price)\r\nols6.r2 <- 1 - mean((pred.lm6 - test$price)^2) / mean((test.avg - test$price)^2)\r\ncat(\"R-square:\" , ols6.r2)\r\n\r\n\r\nR-square: 0.9018549\r\n\r\nsummary(fit.lm6)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = price ~ carat + cut + color + clarity + depth + \r\n    table, data = train)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-19653.8   -688.0   -170.4    544.8   9060.2 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)  -63.005    460.159  -0.137    0.891    \r\ncarat       8785.224     15.184 578.591  < 2e-16 ***\r\ncut          132.378      6.884  19.229  < 2e-16 ***\r\ncolor       -316.898      3.931 -80.612  < 2e-16 ***\r\nclarity      515.401      4.207 122.510  < 2e-16 ***\r\ndepth        -50.059      5.086  -9.842  < 2e-16 ***\r\ntable        -24.234      3.557  -6.813 9.69e-12 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 1226 on 37737 degrees of freedom\r\nMultiple R-squared:  0.9053,    Adjusted R-squared:  0.9053 \r\nF-statistic: 6.015e+04 on 6 and 37737 DF,  p-value: < 2.2e-16\r\n\r\nI pick this model\r\nprice = -7.165 + 8776.430carat + 165.511cut - 318.820color - 518.648clarity\r\n\r\n\r\nfit.lm4 <- lm(price ~ carat+cut+color+clarity, data = train)\r\n\r\nfit.lm4  %>% \r\n  broom::tidy()\r\n\r\n\r\n# A tibble: 5 x 5\r\n  term        estimate std.error statistic   p.value\r\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\r\n1 (Intercept)   -4675.     32.9     -142.  0        \r\n2 carat          8776.     15.1      581.  0        \r\n3 cut             166.      5.79      28.6 9.81e-178\r\n4 color          -319.      3.93     -81.1 0        \r\n5 clarity         519.      4.20     124.  0        \r\n\r\nfit.lm4  %>% \r\n  broom::augment()\r\n\r\n\r\n# A tibble: 37,744 x 11\r\n   price carat   cut color clarity .fitted .resid      .hat .sigma\r\n   <int> <dbl> <dbl> <dbl>   <dbl>   <dbl>  <dbl>     <dbl>  <dbl>\r\n 1  3985  0.93     5     5       3   4276. -291.  0.0000915  1228.\r\n 2  1046  0.31     4     4       7   1063.  -17.0 0.000122   1228.\r\n 3  2959  0.7      3     3       5   3602. -643.  0.0000627  1228.\r\n 4  4876  1.01     5     5       3   4979. -103.  0.0000909  1228.\r\n 5   630  0.3      1     2       3   -958. 1588.  0.000279   1228.\r\n 6   462  0.26     5     5       5   -566. 1028.  0.000118   1228.\r\n 7   734  0.31     4     2       5    663.   70.7 0.0000691  1228.\r\n 8  2936  0.74     5     3       4   3765. -829.  0.0000560  1228.\r\n 9  1294  0.44     5     1       5   2289. -995.  0.000117   1228.\r\n10  4201  0.91     4     5       4   4454. -253.  0.0000450  1228.\r\n# ... with 37,734 more rows, and 2 more variables: .cooksd <dbl>,\r\n#   .std.resid <dbl>\r\n\r\nfit.lm4  %>% \r\n  broom::glance()\r\n\r\n\r\n# A tibble: 1 x 12\r\n  r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC\r\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>\r\n1     0.905         0.905 1228.    89963.       0     4 -3.22e5 6.44e5\r\n# ... with 4 more variables: BIC <dbl>, deviance <dbl>,\r\n#   df.residual <int>, nobs <int>\r\n\r\npred.lm4 <- predict(fit.lm4, test)\r\nmean((pred.lm4 - test$price)^2)\r\n\r\n\r\n[1] 1560832\r\n\r\nols4.r2 <- 1 - mean((pred.lm4 - test$price)^2) / mean((mean(test$price) - test$price)^2)\r\ncat(\"R-square:\" , ols4.r2)\r\n\r\n\r\nR-square: 0.9017074\r\n\r\nsummary(fit.lm4)\r\n\r\n\r\n\r\nCall:\r\nlm(formula = price ~ carat + cut + color + clarity, data = train)\r\n\r\nResiduals:\r\n     Min       1Q   Median       3Q      Max \r\n-19729.3   -688.2   -169.5    542.3   9071.3 \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) -4674.997     32.876 -142.20   <2e-16 ***\r\ncarat        8776.430     15.103  581.09   <2e-16 ***\r\ncut           165.511      5.791   28.58   <2e-16 ***\r\ncolor        -318.820      3.930  -81.11   <2e-16 ***\r\nclarity       518.648      4.199  123.51   <2e-16 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 1228 on 37739 degrees of freedom\r\nMultiple R-squared:  0.9051,    Adjusted R-squared:  0.9051 \r\nF-statistic: 8.996e+04 on 4 and 37739 DF,  p-value: < 2.2e-16\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-01T18:14:16-05:00"
    },
    {
      "path": "index.html",
      "title": "Kanyanee's Project",
      "description": "Welcome to the website. I hope you enjoy it!\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-01T18:14:18-05:00"
    },
    {
      "path": "projects.html",
      "title": "Projects",
      "author": [],
      "contents": "\r\nDiamond price project\r\nThis project use regression analysis to predict diamond price. Link\r\nQQ-Plot R Shiny\r\nThis is si\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-01T18:14:19-05:00"
    }
  ],
  "collections": []
}
